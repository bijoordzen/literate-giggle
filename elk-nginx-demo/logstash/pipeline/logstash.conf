input {
  file {
    path => "/usr/share/logstash/pipeline/nginx.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
  }
}

filter {
  # Match Nginx common log format
  grok {
    match => {
      "message" => "%{IPORHOST:client_ip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] \"%{WORD:method} %{DATA:request} HTTP/%{NUMBER:http_version}\" %{NUMBER:status} %{NUMBER:bytes}( \"%{DATA:referrer}\")?( \"%{DATA:agent}\")?"
    }
    # If grok fails, tag the event
    tag_on_failure => ["_grokparsefailure"]
  }

  # Convert timestamp to Logstash @timestamp
  date {
    match => ["timestamp", "dd/MMM/yyyy:HH:mm:ss Z"]
    target => "@timestamp"
    timezone => "UTC"
  }

  # Convert numeric fields to integers
  mutate {
    convert => { "status" => "integer" }
    convert => { "bytes" => "integer" }
  }

  # Optional: remove the original timestamp field
  mutate {
    remove_field => ["timestamp"]
  }
}

output {
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "nginx-logs"
  }

  stdout { codec => rubydebug }
}
